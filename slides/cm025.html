<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Math 530/630: CM 2.5</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
    <script src="libs/plotly-binding-4.9.0.9000/plotly.js"></script>
    <script src="libs/typedarray-0.1/typedarray.min.js"></script>
    <script src="libs/jquery-1.11.3/jquery.min.js"></script>
    <link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
    <script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
    <link href="libs/plotly-htmlwidgets-css-1.49.4/plotly-htmlwidgets.css" rel="stylesheet" />
    <script src="libs/plotly-main-1.49.4/plotly-latest.min.js"></script>
    <link rel="stylesheet" href="css\ohsu.css" type="text/css" />
    <link rel="stylesheet" href="css\ohsu-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Math 530/630: CM 2.5
## LM Interpretation, Outliers &amp; Diagnostics

---







## Starting with the lab from last class...


```r
glimpse(hate_crimes)
```

```
Observations: 51
Variables: 13
$ state                       &lt;chr&gt; "Alabama", "Alaska", "Arizona", "A...
$ state_abbrev                &lt;chr&gt; "AL", "AK", "AZ", "AR", "CA", "CO"...
$ median_house_inc            &lt;int&gt; 42278, 67629, 49254, 44922, 60487,...
$ share_unemp_seas            &lt;dbl&gt; 0.060, 0.064, 0.063, 0.052, 0.059,...
$ share_pop_metro             &lt;dbl&gt; 0.64, 0.63, 0.90, 0.69, 0.97, 0.80...
$ share_pop_hs                &lt;dbl&gt; 0.821, 0.914, 0.842, 0.824, 0.806,...
$ share_non_citizen           &lt;dbl&gt; 0.02, 0.04, 0.10, 0.04, 0.13, 0.06...
$ share_white_poverty         &lt;dbl&gt; 0.12, 0.06, 0.09, 0.12, 0.09, 0.07...
$ gini_index                  &lt;dbl&gt; 0.472, 0.422, 0.455, 0.458, 0.471,...
$ share_non_white             &lt;dbl&gt; 0.35, 0.42, 0.49, 0.26, 0.61, 0.31...
$ share_vote_trump            &lt;dbl&gt; 0.63, 0.53, 0.50, 0.60, 0.33, 0.44...
$ hate_crimes_per_100k_splc   &lt;dbl&gt; 0.12583893, 0.14374012, 0.22531995...
$ avg_hatecrimes_per_100k_fbi &lt;dbl&gt; 1.8064105, 1.6567001, 3.4139280, 0...
```


---
## Pre-processing


```r
# Pare it down to just what we need
hate_demo &lt;- hate_crimes %&gt;% 
  select(state, avg_hatecrimes_per_100k_fbi, share_pop_hs, gini_index, share_vote_trump) %&gt;%
  mutate(
    cat_trump = case_when(
      share_vote_trump &lt; .5 ~ "less than half", 
      TRUE ~ "more than half"
      )) %&gt;% 
  mutate(cat_trump = as.factor(cat_trump)) %&gt;% 
  select(-share_vote_trump)
```

---
## Model 1: Two numerical predictors


```r
hate_two &lt;- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index + 
                   share_pop_hs,
                 data = hate_demo)

get_regression_table(hate_two)
```

```
# A tibble: 3 x 7
  term         estimate std_error statistic p_value lower_ci upper_ci
  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 intercept       -54.0      9.76     -5.53       0    -73.7    -34.4
2 gini_index       64.3     11.1       5.79       0     42.0     86.7
3 share_pop_hs     31.3      6.81      4.59       0     17.6     45.0
```


---
class: center, middle
## Model 1: Two numerical predictors
&lt;img src="images/lm-whiteboard-process.jpg" width="60%" /&gt;
--
`$$\widehat{\textrm{avg_crimes}} = -54 + 64.3*\textrm{gini_index} + 31.3*\textrm{share_pop_hs}$$`
&lt;br&gt;
--
Is this interpretable? 

&lt;br&gt;
--
Intuitive?



---
## Model 1: Two numerical predictors: centered



```r
hate_two_c &lt;- lm(avg_hatecrimes_per_100k_fbi ~ 
                   I(gini_index-mean(gini_index)) + 
                   I(share_pop_hs-mean(share_pop_hs)),
                 data = hate_demo)

get_regression_table(hate_two_c)
```

```
# A tibble: 3 x 7
  term               estimate std_error statistic p_value lower_ci upper_ci
  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 intercept              2.36     0.187     12.7        0     1.99     2.74
2 I(gini_index - me~    64.3     11.1        5.79       0    42.0     86.7 
3 I(share_pop_hs - ~    31.3      6.81       4.59       0    17.6     45.0 
```


Raw: `\(\widehat{\textrm{avg_crimes}} = -54 + 64.3*\textrm{gini_index} + 31.3*\textrm{share_pop_hs}\)`

Centered: `\(\widehat{\textrm{avg_crimes}} = 2.36 + 64.3*\textrm{centered(gini_index)} + 31.3*\textrm{centered(share_pop_hs)}\)`

---
## Model 1: Two numerical predictors: z-scores


```r
hate_two_z &lt;- lm(avg_hatecrimes_per_100k_fbi ~ 
                   scale(gini_index) + 
                   scale(share_pop_hs),
                 data = hate_demo)

get_regression_table(hate_two_z)
```

```
# A tibble: 3 x 7
  term               estimate std_error statistic p_value lower_ci upper_ci
  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 intercept              2.36     0.187     12.7        0    1.99      2.74
2 scale(gini_index)      1.34     0.232      5.79       0    0.877     1.81
3 scale(share_pop_h~     1.07     0.232      4.59       0    0.599     1.53
```


Raw: `\(\widehat{\textrm{avg_crimes}} = -54 + 64.3*\textrm{gini_index} + 31.3*\textrm{share_pop_hs}\)`

Centered: `\(\widehat{\textrm{avg_crimes}} = 2.36 + 64.3*\textrm{centered(gini_index)} + 31.3*\textrm{centered(share_pop_hs)}\)`

z-scores: `\(\widehat{\textrm{avg_crimes}} = 2.36 + 1.34*\textrm{scaled(gini_index)} + 1.07*\textrm{scaled(share_pop_hs)}\)`


---
## Model 1: Two numerical predictors
&lt;!-- Raw: `\(\widehat{\textrm{avg_crimes}} = -54 + 64.3~ \textrm{gini_index} + 31.3~\textrm{share_pop_hs}\)` --&gt;

&lt;!-- Centered: `\(\widehat{\textrm{avg_crimes}} = 2.36 + 64.3~ \textrm{centered(gini_index)} + 31.3~\textrm{centered(share_pop_hs)}\)` --&gt;

&lt;!-- z-score: `\(\widehat{\textrm{avg_crimes}} = 2.36 + 1.34~ \textrm{scaled(gini_index)} + 1.07~\textrm{scaled(share_pop_hs)}\)` --&gt;


```r
broom::glance(hate_two)
```

```
# A tibble: 1 x 11
  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1     0.432         0.408  1.32      17.9 1.67e-6     3  -83.2  174.  182.
# ... with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;
```

```r
broom::glance(hate_two_c)
```

```
# A tibble: 1 x 11
  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1     0.432         0.408  1.32      17.9 1.67e-6     3  -83.2  174.  182.
# ... with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;
```

```r
broom::glance(hate_two_z)
```

```
# A tibble: 1 x 11
  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1     0.432         0.408  1.32      17.9 1.67e-6     3  -83.2  174.  182.
# ... with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;
```

???
- Compare Model level statistics
- Recall data transformations from 1st class - change location and spread, but not shape

- Or use get_regression_summaries() - need to create the vars rather than scaling on the fly


---
## Model 2: Parallel slopes


```r
hate_para &lt;- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index + 
                   cat_trump,
                 data = hate_demo)

get_regression_table(hate_para)
```

```
# A tibble: 3 x 7
  term               estimate std_error statistic p_value lower_ci upper_ci
  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 intercept           -12.1       4.98      -2.44   0.019   -22.2    -2.12 
2 gini_index           32.5      10.9        2.99   0.004    10.7    54.4  
3 cat_trumpmore tha~   -0.511     0.449     -1.14   0.261    -1.42    0.393
```





---
## Model 2: Parallel slopes



&lt;img src="images/lm-whiteboard-process.jpg" width="60%" /&gt;
--
`$$\widehat{\textrm{avg_crimes}} = -12.1 + 32.5*\textrm{gini_index} - 0.51*\textrm{cat_trump}$$`

--

`$$\widehat{\textrm{avg_crimes}}_{cat\_trump_0} = -12.1 + 32.5*\textrm{gini_index}$$`
`$$\widehat{\textrm{avg_crimes}}_{cat\_trump_1} = -12.61 + 32.5*\textrm{gini_index}$$`

???
- Important to notice that cat_trump is either 0 or 1, so it breaks down into two equations
- However, don't model it that way. Model level statistics will be incorrect

---
## Model 2: Parallel slopes

&lt;img src="cm025_files/figure-html/unnamed-chunk-9-1.png" width="60%" /&gt;

---
## Model 3: Interaction model


```r
hate_int &lt;- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index* 
                   cat_trump,
                 data = hate_demo)

get_regression_table(hate_int)
```

```
# A tibble: 4 x 7
  term               estimate std_error statistic p_value lower_ci upper_ci
  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 intercept             -20.4      5.66     -3.61   0.001   -31.8     -9.02
2 gini_index             50.6     12.4       4.10   0        25.7     75.5 
3 cat_trumpmore tha~     25.7     10.0       2.56   0.014     5.53    45.9 
4 gini_index:cat_tr~    -57.9     22.1      -2.62   0.012  -102.     -13.4 
```

---

## Model 3: Interaction model

&lt;img src="images/lm-whiteboard-3models.jpg" width="60%" /&gt;
--

`$$\widehat{avg\_crimes} = -20.4 + 50.6*gini\_index + 25.7*cat\_trump \\- 57.9*gini\_index*cat\_trump$$`

--

`$$\widehat{avg\_crimes_{cat\_trump=0}} = -20.4 + 50.6*gini\_index$$`
`$$\widehat{avg\_crimes_{cat\_trump=1}} = 5.3 - 7.3*gini\_index$$`


---

## Visualize interaction model

&lt;img src="cm025_files/figure-html/unnamed-chunk-12-1.png" width="60%" /&gt;


---
## Model 3: Center predictors

Would this be easier to interpret after centering the predictor `gini_index`?

`$$\widehat{avg\_crimes_{trump=1}} = 1.98 - 7.3*centered(gini\_index)$$`

`$$\widehat{avg\_crimes_{trump=0}} = 2.54 + 50.6*centered(gini\_index)$$`


```
# A tibble: 4 x 7
  term               estimate std_error statistic p_value lower_ci upper_ci
  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 intercept             2.54      0.299      8.49   0         1.94    3.14 
2 gini_centered        50.6      12.4        4.10   0        25.7    75.5  
3 cat_trumpmore tha~   -0.562     0.424     -1.32   0.192    -1.42    0.292
4 gini_centered:cat~  -57.9      22.1       -2.62   0.012  -102.    -13.4  
```



---
## Model 3: Center predictors

&lt;img src="cm025_files/figure-html/unnamed-chunk-14-1.png" width="60%" /&gt;

---
## Model 4: Continuous interaction


```r
hate_cont &lt;- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index * 
                   share_pop_hs,
                 data = hate_demo)

get_regression_table(hate_cont)
```

```
# A tibble: 4 x 7
  term               estimate std_error statistic p_value lower_ci upper_ci
  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 intercept              42.9      171.     0.25    0.803    -302.     387.
2 gini_index           -147.       374.    -0.395   0.695    -900.     605.
3 share_pop_hs          -78.6      194.    -0.405   0.687    -469.     312.
4 gini_index:share_~    241.       424.     0.567   0.573    -613.    1094.
```

--
*_What??_*

- Coefficients are weird 
- SEs are huge 
- p's aren't significant
- CI contains 0
- But, we added the ability to vary??

---
## Model 4: Continuous interaction


```r
get_regression_table(hate_cont)
```

```
# A tibble: 4 x 7
  term               estimate std_error statistic p_value lower_ci upper_ci
  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 intercept              42.9      171.     0.25    0.803    -302.     387.
2 gini_index           -147.       374.    -0.395   0.695    -900.     605.
3 share_pop_hs          -78.6      194.    -0.405   0.687    -469.     312.
4 gini_index:share_~    241.       424.     0.567   0.573    -613.    1094.
```

```r
broom::glance(hate_cont)
```

```
# A tibble: 1 x 11
  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1     0.436         0.399  1.33      11.9 7.05e-6     4  -83.1  176.  186.
# ... with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;
```


--

- (Multi) collinearity?
- Overall model works "well", but the predictors do not.
- Confused variance! 




???
- Looking at the model level statistics, the model as a whole seems fine
- Problem is that it doesn't know which predictor to assign the variance too, since they are correlated
- Almost always there's a bit when there are multiple predictors - especially risky with interactions
- Centering or scaling might help - might need to remove or combine predictors

---
## Model 4: Continuous interaction - Collinearity



```r
hate_cont_z &lt;- lm(avg_hatecrimes_per_100k_fbi ~ 
                   scale(gini_index) * 
                   scale(share_pop_hs),
                 data = hate_demo)
```


```
# A tibble: 4 x 7
  term               estimate std_error statistic p_value lower_ci upper_ci
  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 intercept             2.46      0.256     9.62    0        1.95     2.98 
2 scale(gini_index)     1.29      0.254     5.06    0        0.775    1.80 
3 scale(share_pop_h~    1.04      0.238     4.36    0        0.56     1.52 
4 scale(gini_index)~    0.171     0.302     0.567   0.573   -0.437    0.779
```

```
# A tibble: 1 x 11
  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1     0.436         0.399  1.33      11.9 7.05e-6     4  -83.1  176.  186.
# ... with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;
```

---
## Model 4: Continuous interaction

Is the interaction needed?

_With interaction term_:
`$$\widehat{\textrm{avg_crimes}} = 2.47 + 1.29~ \textrm{scaled(gini_index)} + 1.04~\textrm{scaled(share_pop_hs)}$$`
`$$+ .171~\textrm{scaled(gini_index)}*\textrm{scaled(share_pop_hs)}$$`
_Without_:
`$$\widehat{\textrm{avg_crimes}} = 2.36 + 1.34~ \textrm{scaled(gini_index)} + 1.07~\textrm{scaled(share_pop_hs)}$$`

_Comparing_:

```r
anova(hate_cont,hate_two_z)
```

```
Analysis of Variance Table

Model 1: avg_hatecrimes_per_100k_fbi ~ gini_index * share_pop_hs
Model 2: avg_hatecrimes_per_100k_fbi ~ scale(gini_index) + scale(share_pop_hs)
  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
1     46 81.190                           
2     47 81.758 -1  -0.56771 0.3216 0.5734
```

---
class: middle, inverse, center


![](https://pbs.twimg.com/media/Ck_mqMOUUAE-mU7.jpg)

---
## Contaminated observation or special snowflake?

* A **contaminated observation** is one that has been damaged in some way. Some examples:
    * Error of execution of the research procedure.
    * Inaccurate measurement of the dependent measure. 
    * Data entry error.
    * Error in calculating a measure.
    * Non-attentive or distracted participants.
* The outlier may simply be an **extremely rare case**. For example, a college freshman might be 12 years old and have an 800 SAT in math. Such an individual is extremely rare, but data is valid.

---
class: middle, inverse, center

![](https://pbs.twimg.com/media/BtmLxH_CUAId7qh.jpg:large)


---
class: middle, inverse, center

![](images/ori-outliers.png)

---
## Definitions

&gt; "Unusual data are problematic in linear models fit by least squares because they can unduly influence the results of the analysis, and because their presence may be a signal that the model fails to capture important characteristics of the data."

* An **outlier** is an observation whose response-variable value is conditionally unusual given the values of the explanatory variables.
* In contrast, a **univariate outlier** is a value of `\(y\)` or `\(x\)` that is unconditionally unusual; such a value may or may not be a regression outlier.

from [John Fox](https://socialsciences.mcmaster.ca/jfox/Courses/Brazil-2009/slides-handout.pdf)

---
## Types of influence

* Extremity on the x’s (leverage)
* Extremity on y (discrepancy)
* Influence on the regression estimates 
    * Global
    * Specific coefficients
--

![](images/fox-outliers.png)
    
---
## Extremity on the `x`: leverage

* Standardized measure of how far the observed value for each observation is from the mean value on the set of `x` values
* Observations with high leverage have the potential to be influential, especially if also extreme on `y`
* The response-variable values are not at all involved in calculating leverage.

---
## Leverage - using hat

* Measure of how unusual the `x` value of a point is, relative to the `x` observations as a whole; leverage describes how unusual an observation is in predictor(s) data.
&lt;!-- * `\(1/n \leq h_i \leq 1\)`.  --&gt;
* If `\(h_{i}\)` is large then the `\(i\)`th observation has considerable impact on the fitted value

SLR:
`$$h_{i} = \frac{1}{n} + \frac{{\left(x_{i} - \bar{x}\right)}^2}{\sum_{j=1}^{n}(x_j - \bar{x})^2}$$`
MLR:

```r
lm_swiss &lt;- lm(Agriculture ~ Examination, swiss)
design_matrix &lt;- model.matrix(lm_swiss)
X &lt;- design_matrix
OLS_estimator &lt;- MASS::ginv(t(X) %*% X) %*% t(X) 
hat_matrix &lt;- X %*% OLS_estimator 

#Assuming an intercept model...
hat &lt;- diag(hat_matrix)    # diagonal of the hat matrix
num_parameters &lt;- sum(hat) # Number of parameters, including the intercept
y_hat &lt;- hat_matrix %*% swiss$Agriculture
```

---
## Start with one model

I'll choose the parallel slopes model


```r
hate_mod &lt;- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index + 
                   cat_trump,
                 data = hate_demo)

get_regression_table(hate_mod)
```

```
# A tibble: 3 x 7
  term               estimate std_error statistic p_value lower_ci upper_ci
  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
1 intercept           -12.1       4.98      -2.44   0.019   -22.2    -2.12 
2 gini_index           32.5      10.9        2.99   0.004    10.7    54.4  
3 cat_trumpmore tha~   -0.511     0.449     -1.14   0.261    -1.42    0.393
```

---
## Diagnostic data frame

Use `data` argument to merge original data with diagnostics



```r
hate_mod &lt;- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index + cat_trump, data = hate_demo)

#hate_mod &lt;- hate_cont_z #or use the centered interaction model
hate_diag &lt;- broom::augment(hate_mod, data = hate_demo) 

glimpse(hate_diag)
```

```
Observations: 50
Variables: 13
$ state                       &lt;chr&gt; "Alabama", "Alaska", "Arizona", "A...
$ avg_hatecrimes_per_100k_fbi &lt;dbl&gt; 1.8064105, 1.6567001, 3.4139280, 0...
$ share_pop_hs                &lt;dbl&gt; 0.821, 0.914, 0.842, 0.824, 0.806,...
$ gini_index                  &lt;dbl&gt; 0.472, 0.422, 0.455, 0.458, 0.471,...
$ cat_trump                   &lt;fct&gt; more than half, more than half, mo...
$ gini_centered               &lt;dbl[,1]&gt; &lt;matrix[25 x 1]&gt;
$ .fitted                     &lt;dbl&gt; 2.691360, 1.066151, 2.138789, 2.23...
$ .se.fit                     &lt;dbl&gt; 0.3892770, 0.4420798, 0.3166400, 0...
$ .resid                      &lt;dbl&gt; -0.88494927, 0.59054912, 1.2751392...
$ .hat                        &lt;dbl&gt; 0.06178909, 0.07968851, 0.04088142...
$ .sigma                      &lt;dbl&gt; 1.577229, 1.580366, 1.571287, 1.56...
$ .cooksd                     &lt;dbl&gt; 7.471722e-03, 4.459757e-03, 9.8213...
$ .std.resid                  &lt;dbl&gt; -0.58339849, 0.39308437, 0.8314164...
```

---
## Leverage


```r
hate_diag %&gt;% 
  select(state, .hat) %&gt;%
  arrange(desc(.hat))
```

```
# A tibble: 50 x 2
   state                  .hat
   &lt;chr&gt;                 &lt;dbl&gt;
 1 District of Columbia 0.306 
 2 New York             0.122 
 3 Utah                 0.112 
 4 New Hampshire        0.0913
 5 Alaska               0.0797
 6 Connecticut          0.0787
 7 Wyoming              0.0770
 8 Wisconsin            0.0768
 9 Louisiana            0.0684
10 Iowa                 0.0671
# ... with 40 more rows
```

---
## Leverage 


```r
k &lt;- 3 # Number of predictors, including the Intercept!
# OR
k &lt;- hate_diag %&gt;% 
  summarize(sum(.hat)) %&gt;% 
  pull() # Numerical property of the hat matrix
mean_hat &lt;- (k)/nrow(hate_demo)
# "large" samples 
hate_diag %&gt;% 
  select(state, .hat) %&gt;%
  filter(.hat &gt; (2*mean_hat))
```

```
# A tibble: 2 x 2
  state                 .hat
  &lt;chr&gt;                &lt;dbl&gt;
1 District of Columbia 0.306
2 New York             0.122
```


```r
# "small" samples
hate_diag %&gt;% 
  select(state, .hat) %&gt;%
  filter(.hat &gt; (3*mean_hat))
```

```
# A tibble: 1 x 2
  state                 .hat
  &lt;chr&gt;                &lt;dbl&gt;
1 District of Columbia 0.306
```

---
## Plot leverage against `x`

&lt;img src="cm025_files/figure-html/unnamed-chunk-26-1.png" width="70%" /&gt;

---
class: middle, inverse, center
## Your turn

With your model, use `broom::augment()` to find observations with high leverage 


---
## Extremity on `y`: discrepancy

* The discrepancy (or `\(distance^2\)`) between each predicted and observed value
* A studentized residual is an observed residual divided by its standard error 
* Two types:
  * Internally studentized (`rstandard` or `broom::.std.resid`): re-normalize the residuals to have unit variance, using a measure of the error variance
  * Externally studentized (`rstudent`): re-normalize the residuals to have unit variance, using a leave-one-out measure of the error variance. This is a measure of the size of the residual, standardized by the estimated standard deviation of residuals based on all the data `but that observation`. Sometimes called jackknifed residuals.
---

###Additional notes on discrepancy:

* High-leverage observations can have small residuals, because these observations can coerce the regression surface to be close to them.
* The formula for the studentized residual is:

`$$t_{i}={\widehat {\varepsilon }_{i} \over \widehat {\sigma }{\sqrt  {1-h_{{ii}}\ }}}$$`

* For internally studentized residuals, `\(\widehat{\sigma}^2\)` is calculated as:

`$$\widehat{\sigma}^2={1 \over n-m}\sum_{j=1}^n \widehat{\varepsilon}_j^{\,2}$$`

* For externally studentized residuals, `\(\widehat{\sigma}_{(i)}^2\)` is calculated as:

`$$\widehat{\sigma}_{(i)}^2={1 \over n-m-1}\sum_{\begin{smallmatrix}j = 1\\j \ne i\end{smallmatrix}}^n \widehat{\varepsilon}_j^{\,2}$$`
---
## Internally studentized residuals

.pull-left[

```r
hate_diag %&gt;% 
  select(state, .std.resid) %&gt;% 
  arrange(.std.resid) %&gt;% 
  slice(1:5)
```

```
# A tibble: 5 x 2
  state        .std.resid
  &lt;chr&gt;             &lt;dbl&gt;
1 Florida           -1.69
2 Pennsylvania      -1.57
3 Georgia           -1.41
4 Mississippi       -1.27
5 Illinois          -1.26
```
]

.pull-right[

```r
hate_diag %&gt;% 
  select(state, .std.resid) %&gt;% 
  arrange(desc(.std.resid)) %&gt;% 
  slice(1:5)
```

```
# A tibble: 5 x 2
  state                .std.resid
  &lt;chr&gt;                     &lt;dbl&gt;
1 District of Columbia       4.45
2 North Dakota               2.18
3 Kentucky                   1.12
4 Washington                 1.07
5 South Dakota               1.04
```
]

---
## Externally studentized residuals

* `rstudent`
* Sadly, not available in `broom::augment`


```r
hate_diag &lt;- hate_diag %&gt;% 
  mutate(.ext.resid = rstudent(hate_mod)) # add 

hate_diag %&gt;% 
  select(state, .std.resid, .ext.resid) %&gt;% 
  arrange(desc(.ext.resid)) %&gt;% 
  slice(1:5)
```

```
# A tibble: 5 x 3
  state                .std.resid .ext.resid
  &lt;chr&gt;                     &lt;dbl&gt;      &lt;dbl&gt;
1 District of Columbia       4.45       5.78
2 North Dakota               2.18       2.27
3 Kentucky                   1.12       1.13
4 Washington                 1.07       1.07
5 South Dakota               1.04       1.04
```

---
## Expect 5% are 2+


```r
hate_diag %&gt;%
  filter(abs(.ext.resid) &gt;= 2) %&gt;%
  select(state, gini_index, .resid, .std.resid, .ext.resid)
```

```
# A tibble: 2 x 5
  state                gini_index .resid .std.resid .ext.resid
  &lt;chr&gt;                     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
1 District of Columbia      0.532   5.80       4.45       5.78
2 North Dakota              0.433   3.32       2.18       2.27
```

2 out of 51 are high:
3.9% of observations with ESR considered to be relatively large
(expected ≈ 2 or 3 observations)

???
Positive or negative
---
class: middle, center
## Your turn

With your model, find observations with high externally studentized residuals (and thus high discrepancy), and compare to the raw residual value, and the internally studentized residual value. What do you notice?

???
Might pull out unexpected points with low residuals and low internally studentized residual

---
class: middle, center
## Your turn 

A common heuristic: 

Influence on Coefficients = Leverage × Discrepancy

Do you have any observations with both high leverage and high discrepancy? 

---
###Leverage and Discrepancy

&lt;img src="cm025_files/figure-html/plot_leverageXdiscrepancy-1.png" width="60%" /&gt;

---
class: middle, center

## Influence on regression estimates

---
## Cook's distance

Global influence

* Influence on regression line, measured by how much the regression line would change if the point were not included in the analysis.
* Cook's distance measures the influence of case `\(i\)` on all `\(n\)` fitted values `\(y_i\)` 
* Cook's distance refers to how far, on average, predicted `\(\hat{y_i}\)` values will move if the observation in question is dropped from the data set


---
## Cook's distance


```r
n &lt;- nrow(hate_demo)
k &lt;- 3 # predictors (including intercept)
d &lt;- 4/(n - k)
d
```

```
[1] 0.08333333
```


```r
hate_diag %&gt;%
  filter(.cooksd &gt; d) %&gt;% 
  select(state, avg_hatecrimes_per_100k_fbi, .cooksd)
```

```
# A tibble: 2 x 3
  state                avg_hatecrimes_per_100k_fbi .cooksd
  &lt;chr&gt;                                      &lt;dbl&gt;   &lt;dbl&gt;
1 District of Columbia                       11.0   2.91  
2 North Dakota                                4.74  0.0923
```

---
## Plot leverage versus Cook's D

&lt;img src="cm025_files/figure-html/unnamed-chunk-33-1.png" width="60%" /&gt;

---
## Plot leverage versus discrepancy, and Cook's D

&lt;img src="cm025_files/figure-html/unnamed-chunk-34-1.png" width="60%" /&gt;
---
## Parallel slopes with and without DC

&lt;img src="cm025_files/figure-html/unnamed-chunk-35-1.png" width="60%" /&gt;

---
## Interaction model with and without DC

&lt;img src="cm025_files/figure-html/unnamed-chunk-36-1.png" width="60%" /&gt;

---
## Specific measures of influence - DFBETAS

* How each individual regression coefficient is changed by deleting each case from the dataset
* Number of DFBETAS is the number of predictors in your model
* Also for the intercept- generally not interesting one bit!
* Recommendation: Look at DFBETAS after Cook’s to isolate which _explanatory_ variables might be unduly influencing your overall regression equation


```r
hate_betas &lt;- hate_diag %&gt;% 
  cbind(dfbetas(hate_mod))
```



---
## Summing up diagnostics




&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Influence &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Index &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Function &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Leverage &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Hat values &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; .hat from broom::augment &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Discrepancy &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Externally studentized residual &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; rstudent(model) within mutate &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Global influence &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Cook's d &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; .cooksd from broom::augment &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Specific influence &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; DFBETAS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; dfbetas(model) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


---

##How to read autoplot


```r
library(ggfortify)
autoplot(hate_mod, label.size = 3)
```

&lt;img src="cm025_files/figure-html/unnamed-chunk-40-1.png" width="60%" /&gt;

---
##How to read autoplot

The plot in the _upper left_ shows the residual errors plotted versus their fitted values. 

The residuals should be randomly distributed around the horizontal line representing a residual error of zero; that is, there should not be a distinct trend in the distribution of points.



---
##How to read autoplot output

The plot in the _upper right_ is a Normal Q-Q plot, which should suggest that the residual errors are normally distributed.



A Q-Q plot displays quantiles of one distribution against quantiles of another. What this means is that the data are ranked and sorted.

* A normal Q-Q plot displays quantiles of the normal distribution on the *x*-axis against quantiles of the empirical (i.e., the observed) distribution on the *y*-axis.
* A straight line is typically plotted through the points corresponding to the 1st and 3rd quantiles of each variable. If the empirical data is normally distributed, all the points on the normal Q-Q plot will form a perfectly straight line.

---
##Q-Q plots




&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Description of Point Pattern &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Possible Interpretation &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; all but a few points fall on line &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; outliers in the data &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; left end sags below line; right end lifts above line &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; long tails at both ends of the data distribution &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; left end lifts above line; right end sags below line &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; short tails at both ends of the data distribution &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; curved pattern with increasing slope (L to R) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; data distribution is skewed to the right &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; curved pattern with decreasing slope (L to R) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; data distribution is skewed to the left &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; staircase pattern (plateaus and gaps) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; data have been rounded or are discrete &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
##How to read autoplot output

The plot in the _lower right_ shows each observation's leverage and standardized residuals. 

Here we don't want to see extreme points in the upper right.

---
##How to read autoplot output

The scale-location plot in the _lower left_ shows the square root of the standardized residuals (sort of a square root of relative error) as a function of the fitted values. 

Again, there should be no obvious trend in this plot.

---
# RMSE

```r
get_regression_summaries(hate_mod)
```

```
# A tibble: 1 x 8
  r_squared adj_r_squared   mse  rmse sigma statistic p_value    df
      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
1     0.199         0.165  2.31  1.52  1.57      5.86   0.005     3
```

  * The root mean square error for regression says how far typical points are above or below the regression line. 
  * The RMSE is to the regression line as the SD is to the average. 
  * For instance, if the scatter diagram is football-shaped,
about 68% of the points on the scatter diagram will be within one RMSE of the regression
line, about 95% of then will be within 2 RMSE of the regression line.
  * The advantage of RMSE metric is that it is more "normalized". Specifically, SSE will increase depending on the amount of the data. 
  * The MSE would not depend on the amount of the data, but the RMSE also expresses the error in the same units as y.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "atelier-lakeside-light",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
