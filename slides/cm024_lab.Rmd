---
title: "CM 2.4 - Multiple linear regression"
subtitle: Math 530/630
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---


```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE,
  comment = NA, fig.width = 4, fig.height = 4)
```


# Logistics

- A complete knitted `html` file is due on Sakai by beginning of the next class. 
- This lab is structured to be similar to this [Case Study on Seattle House Prices from ModernDive](https://moderndive.com/11-thinking-with-data.html#seattle-house-prices). Please open it and follow along with both datasets!
- The structure of this lab is as follows:
  - In the lab, you'll:
      - Complete and interpret EDA Part I (univariate)
      - Complete and interpret EDA Part II (bivariate)
      - Fit a regression model, obtain the regression table, and attempt to interpret the three values that define the regression plane
  - In the next class, together we'll review the above models and: 
      - Perform analysis of observed/fitted values and residuals following [ModernDive](https://moderndive.com/6-multiple-regression.html#model3points)
      - Explore residual analysis following [ModernDive](https://moderndive.com/6-multiple-regression.html#model3residuals)
      

# Overview

We'll work with data from this [538 article](https://fivethirtyeight.com/features/higher-rates-of-hate-crimes-are-tied-to-income-inequality/). In the article, the authors describe collecting data on key socioeconomic factors for each state, including indicators for:

- education (percent of adults 25 and older with at least a high school degree, as of 2009) 
- diversity
    - percent nonwhite population (2015), and 
    - percent noncitizen population (2015).
- geographic heterogeneity (percent population in metropolitan areas, 2015)
- economic health 
    - median household income, 
    - 2016 seasonally adjusted unemployment (September 2016), 
    - percent poverty among white people (2015), and 
    - income inequality (as measured by the Gini index, 2015)
- percent of the population voted for Donald Trump. 

In this lab, we'll use a subset of these variables to predict hate crimes in the US. There are two possible outcome variables here: (1) pre-election data from the FBI, and (2) post-election data from the Southern Poverty Law Center. We'll focus on the pre-election data in this lab.

# The Data

This data is included in the `fivethirtyeight` package in the [`hate_crimes` data frame](https://fivethirtyeight-r.netlify.com/reference/hate_crimes.html), which we’ll refer to as the “Hate crimes” dataset. You can use [`?hate_crimes`](https://fivethirtyeight-r.netlify.com/reference/hate_crimes.html) to read more about it and the variables.

You'll need to load these packages to do this lab:

```{r load_packages}
library(fivethirtyeight) # new to you!
library(moderndive)
library(skimr)
library(tidyverse)
library(GGally) # new to you!
```


We'll use `hate_crimes` to demonstrate multiple regression with:

1. A numerical outcome variable $y$, in this case average annual hate crimes per 100,000 population, FBI, 2010-2015 (`avg_hatecrimes_per_100k_fbi`)
1. Three possible explanatory variables:
    1. A first numerical explanatory variable $x_1$: percent of adults in each state 25 and older with at least a high school degree (2009) (`share_pop_hs`)
    1. A second numerical explanatory variable $x_2$: each state's income inequality (as measured by the Gini index, 2015) (`gini_index`) 
    1. A third numerical explanatory variable $x_3$: each state's percent population that voted for Donald Trump (`share_vote_trump`). At a later stage, we'll convert this variable to a factor.

```{r include = FALSE}
ggplot(hate_crimes, aes(x = avg_hatecrimes_per_100k_fbi, 
                        y = hate_crimes_per_100k_splc)) +
  geom_point() +
  geom_smooth(method = "lm")

ggplot(filter(hate_crimes, !state == "District of Columbia"), 
              aes(x = avg_hatecrimes_per_100k_fbi, 
                  y = hate_crimes_per_100k_splc)) +
  geom_point() +
  geom_smooth(method = "lm")
```

# EDA, Part I

Recall that a [new exploratory data analysis](https://moderndive.com/5-regression.html#model1EDA) involves three things:

* Looking at the raw values and the structure of the data.
* Computing summary statistics of the variables of interest.
* Creating informative visualizations.

General functions we use below- add narrative to interpret each!:

- `dplyr::glimpse()`
- `skimr::skim()`
- `ggplot2::ggplot()`
    - `geom_histogram()` or `geom_density()` for numeric continuous variables
    - `geom_bar()` or `geom_col()` for categorical variables

At this stage, you may also find your want to use `filter`, `mutate`, `arrange`, `select`, or `count`. Let your questions lead you! Feel free to add onto the EDA that follows.


## Look at the raw values

- How many states are here? Are they all "states"?

```{r eval=FALSE}
glimpse(hate_crimes)
```

- How many rows do we have per state? Is there ever more than 1 row per state?

```{r eval=FALSE}
hate_crimes %>% 
  count(state, sort = TRUE)
```


## Compute summary statistics

Let's select just the variables we need first.

```{r}
hate_demo <- hate_crimes %>% 
  select(state, avg_hatecrimes_per_100k_fbi, share_pop_hs, gini_index, 
         share_vote_trump) 
```

Following the narrative in [ModernDive](https://moderndive.com/6-multiple-regression.html#model3EDA), write a few sentences describing the output here.

```{r eval=FALSE}
skim(hate_demo)
```

## Create informative visualizations

First let's look at the outcome variable:

```{r eval=FALSE}
# Density of hate crimes (DV):
ggplot(hate_demo, aes(x = avg_hatecrimes_per_100k_fbi)) +
  geom_density() +
  labs(x = "", title = "Hate Crimes")
```
```{r include=FALSE}
ggplot(hate_demo, aes( y = avg_hatecrimes_per_100k_fbi, x=NA)) + 
  geom_boxplot(outlier.shape = NA) + 
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  geom_dotplot(binaxis = 'y', 
               stackdir = 'center', 
               stackratio = 1.5, 
               binwidth = .1,
               dotsize = 2,
               alpha = .75, 
               fill = "lightseagreen", 
               colour = "lightseagreen",
               na.rm = TRUE) 
```


Next we'll look at our three explanatory variables as continuous:

```{r eval=FALSE}
# Histogram of share_pop_hs (IV):
ggplot(hate_demo, aes(x = share_pop_hs)) +
  geom_density() +
  labs(x = "", title = "HS")

# Histogram of gini (IV):
ggplot(hate_demo, aes(x = gini_index)) +
  geom_density() +
  labs(x = "", title = "Gini")

# Histogram of trump (IV):
ggplot(hate_demo, aes(x = share_vote_trump)) +
  geom_density() +
  labs(x = "", title = "Trump")
```

Let's make `share_vote_trump` a categorical variable:

```{r}
hate_demo <- hate_demo %>% 
  mutate(
    cat_trump = case_when(
      share_vote_trump < .5 ~ "less than half", 
      TRUE ~ "more than half"
      )) %>% 
  mutate(cat_trump = as.factor(cat_trump)) %>% 
  select(-share_vote_trump)
```

> Following the narrative in [ModernDive](https://moderndive.com/11-thinking-with-data.html#house-prices-EDA-I), write a few sentences describing the output here.

# EDA, Part II

Part I of this EDA was univariate in nature in that we only considered one variable at a time. The goal of modeling, however, is to explore relationships between variables. Specifically, we care about bivariate relationships between pairs of variables. But with 1 outcome and 3 explanatory variables, that means we have $3 \times 2 = 6$ correlations to compute. 

For simple regression, we calculated correlation coefficients between the outcome and explanatory variables. For [multiple regression](https://moderndive.com/6-multiple-regression.html#model3EDA), your EDA should involve multiple correlation coefficients. We'll use the `cor()` function to do this. You'll want to first `select` only numeric variables first.

Use this code as an example:

```{r eval = FALSE}
data %>% 
  select(-my_char_var, -my_factor_var) %>% 
  cor()
```

To produce this output:

```{r eval = TRUE, echo = FALSE}
hate_demo %>% 
  select(-state, -cat_trump) %>% 
  cor()
```

Lots of `NA` correlations though! Try this code instead:

```{r eval = FALSE}
data %>% 
  select(-my_char_var, -my_factor_var) %>% 
  cor(., use = "pairwise.complete.obs")
```

```{r include = FALSE}
hate_demo %>% 
  select(-state, -cat_trump) %>%  
  cor(., use = "pairwise.complete.obs")

hate_crimes %>% 
  select(avg_hatecrimes_per_100k_fbi, share_pop_hs, gini_index, share_vote_trump) %>%  
  cor(., use = "pairwise.complete.obs")
```


You could do the same thing in the `corrr` package, using the `correlate` function:

```{r eval = FALSE}
library(corrr)
data %>% 
  select(-my_char_var, -my_factor_var) %>% 
  correlate()
```

We also want to create scatterplots to see the association between each pair of variables in the model (both between the explanatory and the outcome, but also between all explanatory variables with each other). Let's start with the `gini_index`:

```{r echo = FALSE, eval=TRUE}
ggplot(hate_demo, aes(x = gini_index, y = avg_hatecrimes_per_100k_fbi)) +
  geom_point() +
  geom_text(data = filter(hate_demo, state == "District of Columbia"), 
            aes(label = state), hjust = 1, vjust = 1)
```


That's a lot of plots! However, we can actually do all of these comparisons with one function! We'll use `GGally::ggpairs()` to create a pairwise comparison of multivariate data. This includes what is known as a "Generalized Pairs Plot" which is an improved version of a [scatterplot matrix](https://www.rdocumentation.org/packages/graphics/versions/3.5.1/topics/pairs). This function provides two different comparisons of each pair of columns, and displays either the density (continuous numeric) or count (factors) of the respective variable along the diagonal. You can read more about the function and package [here](http://ggobi.github.io/ggally/#ggallyggpairs). 

There are three pieces to the output: `lower`, `upper`, and `diag`. Read more about the sections of the [matrix here](http://ggobi.github.io/ggally/#matrix_sections).

Here is how you can use the function:

```{r eval = FALSE}
data %>% 
  select(-my_char_var) %>% 
  ggpairs()
```

```{r include = FALSE}
hate_demo %>% 
  select(-state) %>% 
  ggpairs()
```


And here is some demo output of how to use it using a dataset called `tips`:

```{r include=TRUE}
data(tips, package = "reshape")
tips %>% 
  select(total_bill, time, tip) %>% 
  ggpairs()
```

And it builds from `ggplot2`, so you can add aesthetic mappings for color, etc. Hurray!

```{r include = TRUE}
tips %>% 
  ggpairs(., aes(color = sex),
          columns = c("total_bill", "time", "tip"))
```

> Calculate all the correlation coefficients.
> Make a `ggpairs` plot between all explanatory and outcome variables.
> Following this narrative in [ModernDive](https://moderndive.com/6-multiple-regression.html#model3EDA), write a few sentences describing the output here.

```{r include = FALSE}
hate_demo %>% 
  select(-state) %>% 
  ggpairs(., aes(color=cat_trump),
          columns=c("avg_hatecrimes_per_100k_fbi", "share_pop_hs", "gini_index"))
```
```{r include = FALSE}
hate_demo %>% 
  select(-state) %>% 
  ggpairs(., aes(color=cat_trump))
```

# Multiple regression models

Do the following:

- Fit a multiple regression model and get the regression table. You'll be assigned **one** of the following models:
    1. Two numerical predictors with a `+` (`gini_index` and `share_pop_hs`)
    1. One numerical / one categorical with parallel slopes (`gini_index` and `cat_trump`)
    1. One numerical / one categorical interaction model (`gini_index` and `cat_trump`)
    1. Two numerical predictors with a `*` (`gini_index` and `share_pop_hs`)
- Sketch out the *modeling equation* for your model (not in your R Markdown)
    - Parallel slopes example [here](https://moderndive.com/6-multiple-regression.html#model4table)
    - Interaction model [here](https://moderndive.com/6-multiple-regression.html#model4interactiontable)
- Interpret the output from the regression table (in complete sentences, but you may use bullet points to organize)
    - Parallel slopes example [here](https://moderndive.com/6-multiple-regression.html#model4table)
    - Interaction model [here](https://moderndive.com/6-multiple-regression.html#model4interactiontable)
- Compare the coefficients from your multiple regression model to the "simple" correlation coefficients for each explanatory variable. Recall that in a simple linear regression: 

$$b_{x_1} = r_{x_1~y} ~\frac{s_y}{s_{x_1}}$$

- For those with the two numerical predictors, you may want to look into making a [3D scatterplot](https://plot.ly/r/3d-scatter-plots/).
    - The numerical outcome variable $y$ `avg_hatecrimes_per_100k_fbi` goes on the z-axis (vertical axis)
    - The two numerical explanatory variables form the "floor" axes. In this case
        - The first numerical explanatory variable $x_1$ `share_vote_hs` is on of the floor axes.
        - The second numerical explanatory variable $x_2$ `gini_index` is on the other floor axis.

```{r eval = FALSE}
library(plotly)
dim_scatter <- plot_ly(hate_demo, 
                       x = ~share_pop_hs, 
                       y = ~gini_index, 
                       z = ~avg_hatecrimes_per_100k_fbi) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'HS'),
                     yaxis = list(title = 'Gini'),
                     zaxis = list(title = 'Hate Crimes')))
dim_scatter
```

```{r include = FALSE}

library(broom)
#
hate_model1 <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index + 
                   share_pop_hs,
                 data = hate_demo)

get_regression_table(hate_model1)

#mean
hate_model1m <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   I(gini_index-mean(gini_index)) + 
                   I(share_pop_hs-mean(share_pop_hs)),
                 data = hate_demo)

get_regression_table(hate_model1m)

#z
hate_model1z <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   scale(gini_index) + 
                   scale(share_pop_hs),
                 data = hate_demo)

get_regression_table(hate_model1z)

#
hate_model2 <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index + 
                   cat_trump,
                data = hate_demo)

get_regression_table(hate_model2)

#
hate_model3 <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   gini_index * 
                   cat_trump,
                data = hate_demo)

get_regression_table(hate_model3)

hate_model3c <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   I(gini_index - mean(gini_index))* 
                   cat_trump,
                 data = hate_demo)

#what if I just do two models??
hate_model3c_0 <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   I(gini_index - mean(gini_index)),
                 data = hate_demo[hate_demo$cat_trump=="less than half",])

hate_model3c_1 <- lm(avg_hatecrimes_per_100k_fbi ~ 
                   I(gini_index - mean(gini_index)), 
                 data = hate_demo[hate_demo$cat_trump=="more than half",])
tidy(hate_model3c)
tidy(hate_model3c_0)
tidy(hate_model3c_1)
glance(hate_model3c)
glance(hate_model3c_0)
glance(hate_model3c_1)

#
hate_model4 <- lm(avg_hatecrimes_per_100k_fbi ~ 
                  gini_index * 
                  share_pop_hs,
                data = hate_demo)

get_regression_table(hate_model4)

hate_model4z <- lm(avg_hatecrimes_per_100k_fbi ~ 
                  scale(gini_index) * 
                  scale(share_pop_hs),
                data = hate_demo)

get_regression_table(hate_model4z)
```








