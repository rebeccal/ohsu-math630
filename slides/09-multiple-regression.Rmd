---
title: "09-regression"
author: "Student Name"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include = FALSE}
# set up global options here
knitr::opts_chunk$set(fig.path = 'Figs/', 
                      warning = FALSE, 
                      message = FALSE, 
                      eval = FALSE)
options(scipen = 999)
```

Install any of these packages if you don't have them.

```{r load_packages, eval = FALSE}
library(dplyr) #for manipulating
library(ggplot2) #for plotting
library(broom) #for dealing with lm output
library(readr) #importing data
library(janitor) #mainly clean_names function
library(car) #Companion to Applied Regression
library(ggfortify) # for autoplot
```

# Load the dataset

```{r swiss}
swiss <- swiss %>% 
  clean_names
```

# Explore the dataset

The dataset is the `swiss` dataset, and is built into R. Find the column names that correspond to the outcome variable (fertility) and the predictor variables (agriculture)

```{r explore-swiss}
# your code goes here
```

# Make a scatterplot

The response variable (Y) goes on the y-axis, and the predictor variable (X) goes on the x-axis. Add the linear regression line to your scatterplot.

```{r scatterplot}
# your code goes here
```


# Build a linear regression model

```{r model}
agr_mod <- lm()
```

# Examine the observations

Use `broom::augment` to examine the observation-level statistics like fitted values, residuals, etc. Here, each row is an observation in the original dataset so it is *tidy*.

```{r swiss-augment}
slr_vars <- 
```

# Examine extremity for predictors: leverage

Challenge! In a chunk, use `dplyr` to print a list of the observations with leverage values > 2 times the mean leverage across the full sample. 

```{r swiss-leverage}
# your code goes here
```

Now print a list of the observations with leverage values > 3 times the mean leverage across the full sample. 

```{r swiss-leverage-2}
# your code goes here
```

Make a scatterplot with agriculture on the x-axis and leverage on the y-axis. Try drawling horizontal lines at the values for 2 and 3 times the mean leverage using `geom_hline()`. Use the code below to start.

```{r leverage-plot}
ggplot() +
  geom_text(aes(label = .rownames), size = 3, vjust = 2)
```

# Examine extremity for the outcome: discrepancy

Take your augmented dataset (mine is called `slr_vars`), and add a new column to it using `dplyr::mutate`. 

```{r}
slr_vars <- slr_vars %>%
  mutate(.extsr = rstudent(m1)) # add ESR
```

Generally, we would expect about 5% of observations with an absolute value for externally studentized residuals of greater than or equal to 2. 

In a chunk, print a list of the observations with externally studentized residuals >= 2. How many observations in this sample meet this criteria? How many would you have expected? 

```{r}
# your code goes here
```



Use the `car::outlierTest` function to identify the observation with the largest absolute studentized residual, using Bonferroni adjustment.

```{r}
# your code goes here
```

# Examine influence on the regression estimates

The rule of thumb for identifying observations with high influence according to Cook's distance is those with d > 4/(n - k - 1). Save this number as an object in your R session:

```{r}
n <- nrows()
k <-
d_thresh <- 
```

Plot Cook's distance on the y-axis against leverage on the x-axis.

```{r}
## plot leverage versus cooks d
ggplot() +
  geom_text(aes(label = .rownames), size = 3, vjust = 2) 
```


Recall this was the 4th quadrant produced by `ggfortify::autoplot`

```{r}
autoplot(agr_mod)
```

Do you note any observations with both high leverage and high Cook's d? That is, do you note any observations that are extreme on the predictor (agriculture) AND exert high influence on the regression estimates?
